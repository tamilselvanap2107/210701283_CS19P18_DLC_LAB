{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPOsnsHlXarlpvq1o3y6Ibs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Y9XLSlvbdI5E","executionInfo":{"status":"ok","timestamp":1731349438734,"user_tz":-330,"elapsed":9420,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LeakyReLU, Reshape, Flatten\n","from tensorflow.keras.layers import BatchNormalization, Dropout\n","from tensorflow.keras.models import Sequential\n","import numpy as np\n"]},{"cell_type":"code","source":["def build_generator():\n","    model = Sequential()\n","    model.add(Dense(128, input_dim=100))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(256))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(512))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Dense(784, activation='tanh'))\n","    model.add(Reshape((28, 28, 1)))\n","    return model\n"],"metadata":{"id":"znazWf6dePIf","executionInfo":{"status":"ok","timestamp":1731349512477,"user_tz":-330,"elapsed":633,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def build_discriminator():\n","    model = Sequential()\n","    model.add(Flatten(input_shape=(28, 28, 1)))\n","    model.add(Dense(512))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(Dense(256))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(Dense(1, activation='sigmoid'))\n","    return model\n"],"metadata":{"id":"yiNf9RqLeRhU","executionInfo":{"status":"ok","timestamp":1731349522367,"user_tz":-330,"elapsed":438,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["discriminator = build_discriminator()\n","discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"],"metadata":{"id":"B4HUWX6QeS35","executionInfo":{"status":"ok","timestamp":1731349533568,"user_tz":-330,"elapsed":416,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["discriminator.trainable = False\n","\n","generator = build_generator()\n","gan_input = tf.keras.Input(shape=(100,))\n","generated_image = generator(gan_input)\n","gan_output = discriminator(generated_image)\n","\n","gan = tf.keras.Model(gan_input, gan_output)\n","gan.compile(loss='binary_crossentropy', optimizer='adam')\n"],"metadata":{"id":"JS4wcCdBeXAu","executionInfo":{"status":"ok","timestamp":1731349545097,"user_tz":-330,"elapsed":638,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def train_gan(epochs, batch_size=128, sample_interval=100):\n","    # Load and preprocess the dataset (e.g., MNIST)\n","    (X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n","    X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n","    X_train = np.expand_dims(X_train, axis=3)\n","\n","    valid = np.ones((batch_size, 1))\n","    fake = np.zeros((batch_size, 1))\n","\n","    for epoch in range(epochs):\n","        # Train Discriminator\n","        idx = np.random.randint(0, X_train.shape[0], batch_size)\n","        real_images = X_train[idx]\n","\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        generated_images = generator.predict(noise)\n","\n","        d_loss_real = discriminator.train_on_batch(real_images, valid)\n","        d_loss_fake = discriminator.train_on_batch(generated_images, fake)\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # Train Generator\n","        noise = np.random.normal(0, 1, (batch_size, 100))\n","        g_loss = gan.train_on_batch(noise, valid)\n","\n","        # Print the progress\n","        print(f\"{epoch} [D loss: {d_loss[0]:.4f}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n","\n","        # If at save interval, save generated image samples\n","        if epoch % sample_interval == 0:\n","            sample_images(epoch)\n","\n","def sample_images(epoch, image_grid_rows=4, image_grid_columns=4):\n","    noise = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, 100))\n","    gen_imgs = generator.predict(noise)\n","    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images to [0, 1]\n","\n","    import matplotlib.pyplot as plt\n","    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(4, 4))\n","    count = 0\n","    for i in range(image_grid_rows):\n","        for j in range(image_grid_columns):\n","            axs[i, j].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n","            axs[i, j].axis('off')\n","            count += 1\n","    plt.show()\n"],"metadata":{"id":"65adLEZTeaSS","executionInfo":{"status":"ok","timestamp":1731349557433,"user_tz":-330,"elapsed":393,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["train_gan(epochs=10000, batch_size=64, sample_interval=1000)\n"],"metadata":{"id":"ub_l4W82eqMl","executionInfo":{"status":"ok","timestamp":1731349635044,"user_tz":-330,"elapsed":381,"user":{"displayName":"THRISHA","userId":"14916615004343827204"}}},"execution_count":2,"outputs":[]}]}